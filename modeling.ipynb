{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dfe5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run  \"./env_setup.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf077c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "table = \"phishing_data\"\n",
    "sql = f\"\"\"\n",
    "select *\n",
    "from {username}.{table} pd\n",
    "\"\"\"\n",
    "\n",
    "df = agent.execute_dml(sql)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, f1_score,\n",
    "    roc_auc_score, matthews_corrcoef, cohen_kappa_score\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Prepare dataset\n",
    "X, y = df.drop(\"is_phishing\", axis=1), df[\"is_phishing\"]\n",
    "\n",
    "# Drop non-numeric or large categorical columns\n",
    "for col in [\"attack_state\", \"severity_score\", \"timestamp\", \"source_ip\", \"dest_ip\", \"source_port\", \"dest_port\"]:\n",
    "    X = X.drop(col, axis=1)\n",
    "\n",
    "# Encode categorical columns\n",
    "encoder = LabelEncoder()\n",
    "for col in [\"protocol\", \"tcp_flags\", \"service\", \"is_weekend\"]:\n",
    "    X[col] = encoder.fit_transform(X[col])\n",
    "\n",
    "# Compute scale_pos_weight for extreme imbalance\n",
    "neg_count = sum(y == 0)\n",
    "pos_count = sum(y == 1)\n",
    "scale_pos_weight = neg_count / pos_count  # ~998k / 1.4k â‰ˆ 710\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Storage for metrics\n",
    "acc_scores, roc_auc_scores, mcc_scores, kappa_scores, nir_scores = [], [], [], [], []\n",
    "sensitivity_scores, specificity_scores, f1_scores = [], [], []\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize XGBoost with class weighting\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,              # you mentioned this helped\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    sensitivity = tp / (tp + fn)       # recall for phishing\n",
    "    specificity = tn / (tn + fp)       # true negative rate\n",
    "    most_freq_class = y_test.mode()[0]\n",
    "    nir = (y_test == most_freq_class).mean()\n",
    "    \n",
    "    # Store metrics\n",
    "    acc_scores.append(acc)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    mcc_scores.append(mcc)\n",
    "    kappa_scores.append(kappa)\n",
    "    nir_scores.append(nir)\n",
    "    f1_scores.append(f1)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificity_scores.append(specificity)\n",
    "    \n",
    "    print(f\"Fold {fold} Metrics:\")\n",
    "    print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}, MCC: {mcc:.4f}, Kappa: {kappa:.4f}, NIR: {nir:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    fold += 1\n",
    "\n",
    "# Summary across folds\n",
    "print(\"\\n=== Cross-Validation Summary ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(acc_scores):.4f}\")\n",
    "print(f\"Mean F1-score: {np.mean(f1_scores):.4f}\")\n",
    "print(f\"Mean Sensitivity: {np.mean(sensitivity_scores):.4f}\")\n",
    "print(f\"Mean Specificity: {np.mean(specificity_scores):.4f}\")\n",
    "print(f\"Mean ROC-AUC: {np.mean(roc_auc_scores):.4f}\")\n",
    "print(f\"Mean MCC: {np.mean(mcc_scores):.4f}\")\n",
    "print(f\"Mean Cohen's Kappa: {np.mean(kappa_scores):.4f}\")\n",
    "print(f\"Mean No Information Rate: {np.mean(nir_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbed58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix for the last fold\n",
    "import seaborn as sns\n",
    "\n",
    "# Create confusion matrix from last fold predictions\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create figure and plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Phishing'],\n",
    "            yticklabels=['Normal', 'Phishing'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "\n",
    "plt.title('Confusion Matrix - XGBoost Model (Final Fold)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed confusion matrix metrics\n",
    "print(\"\\n=== Confusion Matrix Breakdown (Final Fold) ===\")\n",
    "print(f\"True Negatives (TN): {tn:,}\")\n",
    "print(f\"False Positives (FP): {fp:,}\")\n",
    "print(f\"False Negatives (FN): {fn:,}\")\n",
    "print(f\"True Positives (TP): {tp:,}\")\n",
    "print(f\"\\nTotal Predictions: {tn + fp + fn + tp:,}\")\n",
    "print(f\"Phishing Detection Rate: {tp / (tp + fn):.2%}\")\n",
    "print(f\"False Alarm Rate: {fp / (fp + tn):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115486b",
   "metadata": {},
   "source": [
    "# Insider Threat Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2afa3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jonahs23/networkInstrusion/.env\n",
      "User:  jonahs23\n",
      "Database:  postgresql://jonahs23:DataSci23@ads1.datasci.vt.edu:5432/ads_db5\n"
     ]
    }
   ],
   "source": [
    "%run  \"./env_setup.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5566d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonahs23/networkInstrusion/PostgresAgent.py:90: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "table = \"network_traffic_history_itd\"\n",
    "sql = f\"\"\"\n",
    "select *\n",
    "from {username}.{table} pd\n",
    "\"\"\"\n",
    "\n",
    "df = agent.execute_dml(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7362716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(\"is_itd\", axis=1), df[\"is_itd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b7455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"attack_state\", \"severity_score\", \"timestamp\", \"source_ip\", \"dest_ip\", \"source_port\", \"dest_port\"]:\n",
    "    X = X.drop(col, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f370f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "for col in [\"protocol\", \"tcp_flags\", \"service\", \"is_weekend\"]:\n",
    "    X[col] = encoder.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7m10ixxthw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (4999980, 21)\n",
      "Target distribution:\n",
      "is_itd\n",
      "0    4998141\n",
      "1       1839\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Features used:\n",
      "['protocol', 'duration', 'packets', 'bytes', 'bytes_per_packet', 'packets_per_second', 'tcp_flags', 'service', 'is_weekend', 'hour_of_day', 'day_of_week', 'bytes_ratio', 'packet_size_variance', 'connection_frequency', 'unique_ports_per_source', 'off_hours', 'is_internal_source', 'is_internal_dest', 'internal_only', 'external_only', 'high_data_volume_off_hours_internal']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, f1_score,\n",
    "    roc_auc_score, matthews_corrcoef, cohen_kappa_score,\n",
    "    classification_report, precision_score, recall_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Display feature information\n",
    "print(f\"Feature shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"\\nFeatures used:\\n{list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jn4ratj6jx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3,999,984\n",
      "Test set size: 999,996\n",
      "\n",
      "Training set target distribution:\n",
      "is_itd\n",
      "0    3998513\n",
      "1       1471\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set target distribution:\n",
      "is_itd\n",
      "0    999628\n",
      "1       368\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]:,}\")\n",
    "print(f\"Test set size: {X_test.shape[0]:,}\")\n",
    "print(f\"\\nTraining set target distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nTest set target distribution:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61fcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ljvu3y4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FOLD 1/5\n",
      "============================================================\n",
      "Training set size: 3,999,984\n",
      "Test set size: 999,996\n",
      "Training ITD cases: 1,472\n",
      "Test ITD cases: 367\n",
      "Nu parameter (expected outlier fraction): 0.000368\n",
      "Training One-Class SVM...\n"
     ]
    }
   ],
   "source": [
    "# Storage for metrics across all folds\n",
    "\n",
    "acc_scores, precision_scores_list, recall_scores_list, f1_scores = [], [], [], []\n",
    "mcc_scores, kappa_scores, nir_scores = [], [], []\n",
    "sensitivity_scores, specificity_scores = [], []\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold}/{n_splits}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape[0]:,}\")\n",
    "    print(f\"Test set size: {X_test.shape[0]:,}\")\n",
    "    print(f\"Training ITD cases: {y_train.sum():,}\")\n",
    "    print(f\"Test ITD cases: {y_test.sum():,}\")\n",
    "    \n",
    "    # Scale features (important for SVM)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Calculate nu parameter (upper bound on fraction of outliers)\n",
    "    nu = y_train.sum() / len(y_train)\n",
    "    print(f\"Nu parameter (expected outlier fraction): {nu:.6f}\")\n",
    "    \n",
    "    # Initialize One-Class SVM model\n",
    "    # nu: approximation of the fraction of outliers\n",
    "    # kernel: RBF kernel for non-linear decision boundary\n",
    "    # gamma: kernel coefficient (scale = 1/(n_features * X.var()))\n",
    "    oc_svm = OneClassSVM(\n",
    "        nu=nu,\n",
    "        kernel='rbf',\n",
    "        gamma='scale',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(\"Training One-Class SVM...\")\n",
    "    oc_svm.fit(X_train_scaled)\n",
    "    \n",
    "    # Make predictions\n",
    "    # One-Class SVM returns +1 for inliers (normal) and -1 for outliers (ITD)\n",
    "    y_pred_svm = oc_svm.predict(X_test_scaled)\n",
    "    # Convert: -1 (outlier/ITD) -> 1, +1 (inlier/normal) -> 0\n",
    "    y_pred = np.where(y_pred_svm == -1, 1, 0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    most_freq_class = y_test.mode()[0]\n",
    "    nir = (y_test == most_freq_class).mean()\n",
    "    \n",
    "    # Store metrics\n",
    "    acc_scores.append(acc)\n",
    "    precision_scores_list.append(precision)\n",
    "    recall_scores_list.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    mcc_scores.append(mcc)\n",
    "    kappa_scores.append(kappa)\n",
    "    nir_scores.append(nir)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificity_scores.append(specificity)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f\"\\nFold {fold} Results:\")\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    print(f\"Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}, Kappa: {kappa:.4f}, NIR: {nir:.4f}\")\n",
    "    print(f\"Confusion Matrix: TN={tn:,}, FP={fp:,}, FN={fn:,}, TP={tp:,}\")\n",
    "    print(f\"ITD Detection Rate: {sensitivity:.2%}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CROSS-VALIDATION SUMMARY\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7mpfadyp5su",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive metrics\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # recall for ITD\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # true negative rate\n",
    "\n",
    "# No Information Rate\n",
    "most_freq_class = y_test.mode()[0]\n",
    "nir = (y_test == most_freq_class).mean()\n",
    "\n",
    "print(\"=== Isolation Forest Model Performance ===\")\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"\\nMatthews Correlation Coefficient: {mcc:.4f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "print(f\"No Information Rate: {nir:.4f}\")\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"True Negatives (TN): {tn:,}\")\n",
    "print(f\"False Positives (FP): {fp:,}\")\n",
    "print(f\"False Negatives (FN): {fn:,}\")\n",
    "print(f\"True Positives (TP): {tp:,}\")\n",
    "print(f\"\\nITD Detection Rate: {sensitivity:.2%}\")\n",
    "print(f\"False Alarm Rate: {fp / (fp + tn):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "nzk161316cb",
   "source": "# Create aggregated confusion matrix from all folds\nimport seaborn as sns\n\n# Sum up confusion matrices from all folds\ntotal_tn = sum([r['tn'] for r in results])\ntotal_fp = sum([r['fp'] for r in results])\ntotal_fn = sum([r['fn'] for r in results])\ntotal_tp = sum([r['tp'] for r in results])\n\n# Create confusion matrix array\ncm_total = np.array([[total_tn, total_fp], \n                     [total_fn, total_tp]])\n\n# Visualize aggregated confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_total, annot=True, fmt='d', cmap='Reds', \n            xticklabels=['Normal', 'Insider Threat'],\n            yticklabels=['Normal', 'Insider Threat'],\n            cbar_kws={'label': 'Count'})\n\nplt.title('Aggregated Confusion Matrix - One-Class SVM (All Folds)', fontsize=14, fontweight='bold')\nplt.ylabel('Actual', fontsize=12)\nplt.xlabel('Predicted', fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# Print detailed confusion matrix breakdown\nprint(\"\\n=== Aggregated Confusion Matrix (All Folds Combined) ===\")\nprint(f\"True Negatives (TN): {total_tn:,}\")\nprint(f\"False Positives (FP): {total_fp:,}\")\nprint(f\"False Negatives (FN): {total_fn:,}\")\nprint(f\"True Positives (TP): {total_tp:,}\")\nprint(f\"\\nTotal Predictions: {total_tn + total_fp + total_fn + total_tp:,}\")\nprint(f\"Overall ITD Detection Rate: {total_tp / (total_tp + total_fn) * 100:.2f}%\")\nprint(f\"Overall False Alarm Rate: {total_fp / (total_fp + total_tn) * 100:.2f}%\")\nprint(f\"Overall Precision: {total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0:.4f}\")\nprint(f\"Overall Recall: {total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irqm3bod3z",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Reds', \n",
    "            xticklabels=['Normal', 'Insider Threat'],\n",
    "            yticklabels=['Normal', 'Insider Threat'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "\n",
    "plt.title('Confusion Matrix - Isolation Forest Model', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u5kgjshnxog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze anomaly scores distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Anomaly score distribution by class\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(anomaly_scores[y_test == 0], bins=50, alpha=0.7, label='Normal', color='blue')\n",
    "plt.hist(anomaly_scores[y_test == 1], bins=50, alpha=0.7, label='Insider Threat', color='red')\n",
    "plt.xlabel('Anomaly Score', fontsize=11)\n",
    "plt.ylabel('Frequency', fontsize=11)\n",
    "plt.title('Anomaly Score Distribution by Class', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Box plot of anomaly scores\n",
    "plt.subplot(1, 2, 2)\n",
    "data_for_box = [anomaly_scores[y_test == 0], anomaly_scores[y_test == 1]]\n",
    "plt.boxplot(data_for_box, labels=['Normal', 'Insider Threat'])\n",
    "plt.ylabel('Anomaly Score', fontsize=11)\n",
    "plt.title('Anomaly Score Box Plot', fontsize=12, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAnomaly Score Statistics:\")\n",
    "print(f\"Normal - Mean: {anomaly_scores[y_test == 0].mean():.4f}, Std: {anomaly_scores[y_test == 0].std():.4f}\")\n",
    "print(f\"Insider Threat - Mean: {anomaly_scores[y_test == 1].mean():.4f}, Std: {anomaly_scores[y_test == 1].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gu0g79ph7am",
   "metadata": {},
   "source": [
    "## Model Summary: One-Class SVM\n",
    "\n",
    "The One-Class SVM model leverages the following key features from `network_traffic_history_itd`:\n",
    "\n",
    "**Engineered Features (from data_preparation):**\n",
    "- `off_hours`: Traffic outside business hours (weekends or before 9am/after 5pm)\n",
    "- `is_internal_source`, `is_internal_dest`: Internal IP address indicators\n",
    "- `internal_only`, `external_only`: Traffic direction flags\n",
    "- `high_data_volume_off_hours_internal`: High data volume during off-hours from internal sources\n",
    "- `ext_transfer`: External data transfer relay patterns\n",
    "\n",
    "**Original Network Features:**\n",
    "- `duration`, `packets`, `bytes`, `bytes_per_packet`\n",
    "- `protocol`, `tcp_flags`, `service`\n",
    "- `bytes_ratio`, `packet_size_variance`, `connection_frequency`\n",
    "\n",
    "**One-Class SVM Approach:**\n",
    "- **Unsupervised anomaly detection** using RBF kernel for non-linear decision boundaries\n",
    "- **Feature scaling** applied via StandardScaler (critical for SVM performance)\n",
    "- **Nu parameter** set to expected proportion of outliers (insider threats)\n",
    "- Creates a hypersphere around normal traffic; anything outside is classified as anomaly\n",
    "- More robust to high-dimensional data compared to Isolation Forest\n",
    "- Better at capturing complex, non-linear relationships in the feature space\n",
    "\n",
    "The One-Class SVM learns the boundary of normal network behavior and flags insider threats as outliers that fall outside this learned boundary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads_5984",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}