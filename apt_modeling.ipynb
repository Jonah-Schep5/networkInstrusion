{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884ce3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jonahs23/networkInstrusion/.env\n",
      "User:  jonahs23\n",
      "Database:  postgresql://jonahs23:DataSci23@ads1.datasci.vt.edu:5432/ads_db5\n"
     ]
    }
   ],
   "source": [
    "%run  \"./env_setup.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b7d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonahs23/networkInstrusion/PostgresAgent.py:90: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dest_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>duration</th>\n",
       "      <th>packets</th>\n",
       "      <th>bytes</th>\n",
       "      <th>bytes_per_packet</th>\n",
       "      <th>tcp_flags</th>\n",
       "      <th>packet_size_variance</th>\n",
       "      <th>connection_frequency</th>\n",
       "      <th>off_hours</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>is_internal_source</th>\n",
       "      <th>is_internal_dest</th>\n",
       "      <th>is_apt</th>\n",
       "      <th>time_period</th>\n",
       "      <th>bytes_percentile</th>\n",
       "      <th>packets_percentile</th>\n",
       "      <th>duration_percentile</th>\n",
       "      <th>bpp_percentile</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>UDP</td>\n",
       "      <td>1.653091</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>53.990147</td>\n",
       "      <td>7.582332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HTTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5887</td>\n",
       "      <td>UDP</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>63.50</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>evening</td>\n",
       "      <td>0.062480</td>\n",
       "      <td>0.029280</td>\n",
       "      <td>0.816123</td>\n",
       "      <td>0.577682</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10853</td>\n",
       "      <td>TCP</td>\n",
       "      <td>0.062681</td>\n",
       "      <td>4</td>\n",
       "      <td>239</td>\n",
       "      <td>59.75</td>\n",
       "      <td>PSH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>evening</td>\n",
       "      <td>0.239041</td>\n",
       "      <td>0.190941</td>\n",
       "      <td>0.638403</td>\n",
       "      <td>0.473302</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30760</td>\n",
       "      <td>UDP</td>\n",
       "      <td>0.072567</td>\n",
       "      <td>4</td>\n",
       "      <td>282</td>\n",
       "      <td>70.50</td>\n",
       "      <td>RST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0.322661</td>\n",
       "      <td>0.190941</td>\n",
       "      <td>0.719683</td>\n",
       "      <td>0.770823</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4730</td>\n",
       "      <td>TCP</td>\n",
       "      <td>0.070041</td>\n",
       "      <td>4</td>\n",
       "      <td>338</td>\n",
       "      <td>84.50</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0.429742</td>\n",
       "      <td>0.190941</td>\n",
       "      <td>0.698803</td>\n",
       "      <td>0.947144</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dest_port protocol  duration  packets  bytes  bytes_per_packet tcp_flags  \\\n",
       "0         80      UDP  1.653091       51     51              1.00       FIN   \n",
       "1       5887      UDP  0.084629        2    127             63.50       FIN   \n",
       "2      10853      TCP  0.062681        4    239             59.75       PSH   \n",
       "3      30760      UDP  0.072567        4    282             70.50       RST   \n",
       "4       4730      TCP  0.070041        4    338             84.50       FIN   \n",
       "\n",
       "   packet_size_variance  connection_frequency  off_hours  ... hour_of_day  \\\n",
       "0                   0.0                     1          1  ...          20   \n",
       "1                   0.0                     1          1  ...          18   \n",
       "2                   0.0                     1          1  ...          18   \n",
       "3                   0.0                     1          1  ...          22   \n",
       "4                   0.0                     1          1  ...          20   \n",
       "\n",
       "   is_internal_source  is_internal_dest  is_apt  time_period bytes_percentile  \\\n",
       "0                   0                 1       0        night         0.008680   \n",
       "1                   0                 1       0      evening         0.062480   \n",
       "2                   0                 1       0      evening         0.239041   \n",
       "3                   0                 1       0        night         0.322661   \n",
       "4                   0                 1       0        night         0.429742   \n",
       "\n",
       "   packets_percentile  duration_percentile  bpp_percentile  service  \n",
       "0           53.990147             7.582332        0.000000     HTTP  \n",
       "1            0.029280             0.816123        0.577682  Unknown  \n",
       "2            0.190941             0.638403        0.473302  Unknown  \n",
       "3            0.190941             0.719683        0.770823  Unknown  \n",
       "4            0.190941             0.698803        0.947144  Unknown  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, f1_score,\n",
    "    roc_auc_score, matthews_corrcoef, cohen_kappa_score\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "table = \"network_traffic_history_apt\"\n",
    "sql = f\"\"\"\n",
    "select dest_port,\n",
    "protocol,\n",
    "duration,\n",
    "packets,\n",
    "bytes,\n",
    "bytes_per_packet,\n",
    "tcp_flags,\n",
    "packet_size_variance,\n",
    "connection_frequency,\n",
    "off_hours,\n",
    "is_weekend,\n",
    "hour_of_day,\n",
    "is_internal_source,\n",
    "is_internal_dest,\n",
    "is_apt,\n",
    "time_period,\n",
    "bytes_percentile,\n",
    "packets_percentile,\n",
    "duration_percentile,\n",
    "bpp_percentile,\n",
    "service\n",
    "\n",
    "from {username}.{table} pd\n",
    "\"\"\"\n",
    "\n",
    "df = agent.execute_dml(sql)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a991591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Check class distribution before SMOTE\\nfrom collections import Counter\\nprint(\"Class distribution before SMOTE:\")\\nprint(f\"Total samples: {len(y):,}\")\\nprint(f\"Class 0 (Normal): {sum(y == 0):,}\")\\nprint(f\"Class 1 (apt): {sum(y == 1):,}\")\\nprint(f\"Imbalance ratio: {sum(y == 0) / sum(y == 1):.2f}:1\")\\nprint(f\"\\nTarget distribution:\\n{Counter(y)}\")\\n\\n# Apply SMOTE to upsample the minority class to 2:1 ratio (Normal:apt)\\nfrom imblearn.over_sampling import SMOTE\\nprint(\"\\nApplying SMOTE upsampling to 2:1 ratio (Normal:apt)...\")\\n\\n# Calculate target ratio: we want Class 0 : Class 1 = 2:1\\n# So Class 1 should be Class 0 / 2\\nminority_target = sum(y == 0) // 10\\n\\nsmote = SMOTE(random_state=42, sampling_strategy={1: minority_target}, k_neighbors=5)\\nX_resampled, y_resampled = smote.fit_resample(X, y)\\n\\n# Check class distribution after SMOTE\\nprint(\"\\nClass distribution after SMOTE:\")\\nprint(f\"Total samples: {len(y_resampled):,}\")\\nprint(f\"Class 0 (Normal): {sum(y_resampled == 0):,}\")\\nprint(f\"Class 1 (apt): {sum(y_resampled == 1):,}\")\\nprint(f\"New ratio: {sum(y_resampled == 0) / sum(y_resampled == 1):.2f}:1\")\\nprint(f\"\\nTarget distribution:\\n{Counter(y_resampled)}\")\\n\\n# Calculate expected NIR after SMOTE\\nexpected_nir = sum(y_resampled == 0) / len(y_resampled)\\nprint(f\"\\nExpected No Information Rate (NIR) after SMOTE: {expected_nir:.4f}\")\\n\\n# Update X and y to use resampled data\\nX = pd.DataFrame(X_resampled, columns=X.columns)\\ny = pd.Series(y_resampled, name=\\'is_apt\\')\\n\\nprint(\"\\nSMOTE upsampling completed successfully!\")\\nprint(f\"Generated {sum(y_resampled == 1) - sum(df[\\'is_apt\\'] == 1):,} synthetic apt samples\")\\nprint(f\"\\nFeatures used:\\n{list(X.columns)}\")'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, prepare the data by separating features and target\n",
    "\n",
    "X, y = df.drop(\"is_apt\", axis=1), df[\"is_apt\"]\n",
    "\n",
    "# Drop non-numeric columns\n",
    "for col in [\"attack_state\"]:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(col, axis=1)\n",
    "\n",
    "# Encode categorical columns\n",
    "\n",
    "\n",
    "'''\n",
    "# Check class distribution before SMOTE\n",
    "from collections import Counter\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(f\"Total samples: {len(y):,}\")\n",
    "print(f\"Class 0 (Normal): {sum(y == 0):,}\")\n",
    "print(f\"Class 1 (apt): {sum(y == 1):,}\")\n",
    "print(f\"Imbalance ratio: {sum(y == 0) / sum(y == 1):.2f}:1\")\n",
    "print(f\"\\nTarget distribution:\\n{Counter(y)}\")\n",
    "\n",
    "# Apply SMOTE to upsample the minority class to 2:1 ratio (Normal:apt)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(\"\\nApplying SMOTE upsampling to 2:1 ratio (Normal:apt)...\")\n",
    "\n",
    "# Calculate target ratio: we want Class 0 : Class 1 = 2:1\n",
    "# So Class 1 should be Class 0 / 2\n",
    "minority_target = sum(y == 0) // 10\n",
    "\n",
    "smote = SMOTE(random_state=42, sampling_strategy={1: minority_target}, k_neighbors=5)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(f\"Total samples: {len(y_resampled):,}\")\n",
    "print(f\"Class 0 (Normal): {sum(y_resampled == 0):,}\")\n",
    "print(f\"Class 1 (apt): {sum(y_resampled == 1):,}\")\n",
    "print(f\"New ratio: {sum(y_resampled == 0) / sum(y_resampled == 1):.2f}:1\")\n",
    "print(f\"\\nTarget distribution:\\n{Counter(y_resampled)}\")\n",
    "\n",
    "# Calculate expected NIR after SMOTE\n",
    "expected_nir = sum(y_resampled == 0) / len(y_resampled)\n",
    "print(f\"\\nExpected No Information Rate (NIR) after SMOTE: {expected_nir:.4f}\")\n",
    "\n",
    "# Update X and y to use resampled data\n",
    "X = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "y = pd.Series(y_resampled, name='is_apt')\n",
    "\n",
    "print(\"\\nSMOTE upsampling completed successfully!\")\n",
    "print(f\"Generated {sum(y_resampled == 1) - sum(df['is_apt'] == 1):,} synthetic apt samples\")\n",
    "print(f\"\\nFeatures used:\\n{list(X.columns)}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd939916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "for col in [\"protocol\", \"tcp_flags\", \"service\", \"time_period\",\"is_weekend\"]:\n",
    "    X[col] = encoder.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c0b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimized XGBoost for Extreme Class Imbalance ===\n",
      "\n",
      "Class distribution:\n",
      "  Normal (0): 4,999,536\n",
      "  apt (1): 444\n",
      "  Imbalance ratio: 11260.2:1\n",
      "  Base contamination: 0.000089\n",
      "\n",
      "Scale_pos_weight: 11260.2\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 10:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,399,590 samples (3,999,628 Normal, 399,962 apt)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ads_5984/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [11:23:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Threshold: 1.0000 | F1: 0.2042 | PR-AUC: 0.1205 | Sens: 0.5000\n",
      "  Fold 2: Training on 4,399,591 samples (3,999,629 Normal, 399,962 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1926 | PR-AUC: 0.1062 | Sens: 0.6404\n",
      "  Fold 3: Training on 4,399,591 samples (3,999,629 Normal, 399,962 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1551 | PR-AUC: 0.0889 | Sens: 0.5506\n",
      "  Fold 4: Training on 4,399,591 samples (3,999,629 Normal, 399,962 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1728 | PR-AUC: 0.0897 | Sens: 0.3146\n",
      "  Fold 5: Training on 4,399,591 samples (3,999,629 Normal, 399,962 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1724 | PR-AUC: 0.1023 | Sens: 0.4494\n",
      "\n",
      "  Ratio 10:1 - Mean Metrics:\n",
      "    Accuracy:    0.9996 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1115\n",
      "    Recall:      0.4910\n",
      "    F1-score:    0.1794\n",
      "    F2-score:    0.2863\n",
      "    Specificity: 0.9996\n",
      "    ROC-AUC:     0.9995\n",
      "    PR-AUC:      0.1015 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2315\n",
      "    Kappa:       0.1793\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 20:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,199,609 samples (3,999,628 Normal, 199,981 apt)\n",
      "    Threshold: 1.0000 | F1: 0.2245 | PR-AUC: 0.1247 | Sens: 0.4886\n",
      "  Fold 2: Training on 4,199,610 samples (3,999,629 Normal, 199,981 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1786 | PR-AUC: 0.1066 | Sens: 0.5169\n",
      "  Fold 3: Training on 4,199,610 samples (3,999,629 Normal, 199,981 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1519 | PR-AUC: 0.0834 | Sens: 0.5393\n",
      "  Fold 4: Training on 4,199,610 samples (3,999,629 Normal, 199,981 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1975 | PR-AUC: 0.0932 | Sens: 0.3596\n",
      "  Fold 5: Training on 4,199,610 samples (3,999,629 Normal, 199,981 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1795 | PR-AUC: 0.0905 | Sens: 0.5506\n",
      "\n",
      "  Ratio 20:1 - Mean Metrics:\n",
      "    Accuracy:    0.9996 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1171\n",
      "    Recall:      0.4910\n",
      "    F1-score:    0.1864\n",
      "    F2-score:    0.2931\n",
      "    Specificity: 0.9997\n",
      "    ROC-AUC:     0.9995\n",
      "    PR-AUC:      0.0997 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2370\n",
      "    Kappa:       0.1863\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 30:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,132,948 samples (3,999,628 Normal, 133,320 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1894 | PR-AUC: 0.1147 | Sens: 0.6705\n",
      "  Fold 2: Training on 4,132,949 samples (3,999,629 Normal, 133,320 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1812 | PR-AUC: 0.1048 | Sens: 0.6180\n",
      "  Fold 3: Training on 4,132,949 samples (3,999,629 Normal, 133,320 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1515 | PR-AUC: 0.0832 | Sens: 0.4944\n",
      "  Fold 4: Training on 4,132,949 samples (3,999,629 Normal, 133,320 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1789 | PR-AUC: 0.0867 | Sens: 0.4382\n",
      "  Fold 5: Training on 4,132,949 samples (3,999,629 Normal, 133,320 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1851 | PR-AUC: 0.0965 | Sens: 0.4607\n",
      "\n",
      "  Ratio 30:1 - Mean Metrics:\n",
      "    Accuracy:    0.9996 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1068\n",
      "    Recall:      0.5363\n",
      "    F1-score:    0.1772\n",
      "    F2-score:    0.2946\n",
      "    Specificity: 0.9996\n",
      "    ROC-AUC:     0.9994\n",
      "    PR-AUC:      0.0972 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2381\n",
      "    Kappa:       0.1771\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 40:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,099,618 samples (3,999,628 Normal, 99,990 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1902 | PR-AUC: 0.1047 | Sens: 0.6591\n",
      "  Fold 2: Training on 4,099,619 samples (3,999,629 Normal, 99,990 apt)\n",
      "    Threshold: 0.9999 | F1: 0.2044 | PR-AUC: 0.1115 | Sens: 0.6854\n",
      "  Fold 3: Training on 4,099,619 samples (3,999,629 Normal, 99,990 apt)\n",
      "    Threshold: 0.9994 | F1: 0.1506 | PR-AUC: 0.0940 | Sens: 0.7528\n",
      "  Fold 4: Training on 4,099,619 samples (3,999,629 Normal, 99,990 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1730 | PR-AUC: 0.0883 | Sens: 0.3596\n",
      "  Fold 5: Training on 4,099,619 samples (3,999,629 Normal, 99,990 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1877 | PR-AUC: 0.0943 | Sens: 0.5506\n",
      "\n",
      "  Ratio 40:1 - Mean Metrics:\n",
      "    Accuracy:    0.9995 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1084\n",
      "    Recall:      0.6015\n",
      "    F1-score:    0.1812\n",
      "    F2-score:    0.3072\n",
      "    Specificity: 0.9995\n",
      "    ROC-AUC:     0.9995\n",
      "    PR-AUC:      0.0986 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2519\n",
      "    Kappa:       0.1810\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 50:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,079,620 samples (3,999,628 Normal, 79,992 apt)\n",
      "    Threshold: 0.9998 | F1: 0.1935 | PR-AUC: 0.1148 | Sens: 0.6818\n",
      "  Fold 2: Training on 4,079,621 samples (3,999,629 Normal, 79,992 apt)\n",
      "    Threshold: 0.9998 | F1: 0.1975 | PR-AUC: 0.1095 | Sens: 0.7191\n",
      "  Fold 3: Training on 4,079,621 samples (3,999,629 Normal, 79,992 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1602 | PR-AUC: 0.0855 | Sens: 0.6067\n",
      "  Fold 4: Training on 4,079,621 samples (3,999,629 Normal, 79,992 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1832 | PR-AUC: 0.0888 | Sens: 0.4045\n",
      "  Fold 5: Training on 4,079,621 samples (3,999,629 Normal, 79,992 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1837 | PR-AUC: 0.0982 | Sens: 0.5056\n",
      "\n",
      "  Ratio 50:1 - Mean Metrics:\n",
      "    Accuracy:    0.9995 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1100\n",
      "    Recall:      0.5836\n",
      "    F1-score:    0.1836\n",
      "    F2-score:    0.3092\n",
      "    Specificity: 0.9996\n",
      "    ROC-AUC:     0.9990\n",
      "    PR-AUC:      0.0993 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2515\n",
      "    Kappa:       0.1835\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 75:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,052,956 samples (3,999,628 Normal, 53,328 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1741 | PR-AUC: 0.0974 | Sens: 0.3977\n",
      "  Fold 2: Training on 4,052,957 samples (3,999,629 Normal, 53,328 apt)\n",
      "    Threshold: 0.9998 | F1: 0.1935 | PR-AUC: 0.1067 | Sens: 0.7416\n",
      "  Fold 3: Training on 4,052,957 samples (3,999,629 Normal, 53,328 apt)\n",
      "    Threshold: 0.9998 | F1: 0.1566 | PR-AUC: 0.0920 | Sens: 0.6404\n",
      "  Fold 4: Training on 4,052,957 samples (3,999,629 Normal, 53,328 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1687 | PR-AUC: 0.0820 | Sens: 0.4719\n",
      "  Fold 5: Training on 4,052,957 samples (3,999,629 Normal, 53,328 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1716 | PR-AUC: 0.0905 | Sens: 0.5843\n",
      "\n",
      "  Ratio 75:1 - Mean Metrics:\n",
      "    Accuracy:    0.9995 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1030\n",
      "    Recall:      0.5672\n",
      "    F1-score:    0.1729\n",
      "    F2-score:    0.2939\n",
      "    Specificity: 0.9996\n",
      "    ROC-AUC:     0.9994\n",
      "    PR-AUC:      0.0937 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2397\n",
      "    Kappa:       0.1728\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 100:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,039,624 samples (3,999,628 Normal, 39,996 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1907 | PR-AUC: 0.1067 | Sens: 0.5114\n",
      "  Fold 2: Training on 4,039,625 samples (3,999,629 Normal, 39,996 apt)\n",
      "    Threshold: 0.9997 | F1: 0.1874 | PR-AUC: 0.1048 | Sens: 0.7191\n",
      "  Fold 3: Training on 4,039,625 samples (3,999,629 Normal, 39,996 apt)\n",
      "    Threshold: 0.9995 | F1: 0.1582 | PR-AUC: 0.0828 | Sens: 0.7303\n",
      "  Fold 4: Training on 4,039,625 samples (3,999,629 Normal, 39,996 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1595 | PR-AUC: 0.0829 | Sens: 0.4157\n",
      "  Fold 5: Training on 4,039,625 samples (3,999,629 Normal, 39,996 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1806 | PR-AUC: 0.0916 | Sens: 0.4719\n",
      "\n",
      "  Ratio 100:1 - Mean Metrics:\n",
      "    Accuracy:    0.9995 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1048\n",
      "    Recall:      0.5697\n",
      "    F1-score:    0.1753\n",
      "    F2-score:    0.2962\n",
      "    Specificity: 0.9996\n",
      "    ROC-AUC:     0.9992\n",
      "    PR-AUC:      0.0938 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2418\n",
      "    Kappa:       0.1752\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 150:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,026,292 samples (3,999,628 Normal, 26,664 apt)\n",
      "    Threshold: 1.0000 | F1: 0.1974 | PR-AUC: 0.1072 | Sens: 0.3409\n",
      "  Fold 2: Training on 4,026,293 samples (3,999,629 Normal, 26,664 apt)\n",
      "    Threshold: 0.9996 | F1: 0.2006 | PR-AUC: 0.1204 | Sens: 0.7528\n",
      "  Fold 3: Training on 4,026,293 samples (3,999,629 Normal, 26,664 apt)\n",
      "    Threshold: 0.9998 | F1: 0.1721 | PR-AUC: 0.0864 | Sens: 0.5955\n",
      "  Fold 4: Training on 4,026,293 samples (3,999,629 Normal, 26,664 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1696 | PR-AUC: 0.0879 | Sens: 0.4831\n",
      "  Fold 5: Training on 4,026,293 samples (3,999,629 Normal, 26,664 apt)\n",
      "    Threshold: 0.9999 | F1: 0.1988 | PR-AUC: 0.1023 | Sens: 0.5618\n",
      "\n",
      "  Ratio 150:1 - Mean Metrics:\n",
      "    Accuracy:    0.9996 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1158\n",
      "    Recall:      0.5468\n",
      "    F1-score:    0.1877\n",
      "    F2-score:    0.3050\n",
      "    Specificity: 0.9996\n",
      "    ROC-AUC:     0.9995\n",
      "    PR-AUC:      0.1008 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2481\n",
      "    Kappa:       0.1876\n",
      "\n",
      "======================================================================\n",
      "Testing Ratio: 200:1 (Normal:apt)\n",
      "======================================================================\n",
      "  Fold 1: Training on 4,019,626 samples (3,999,628 Normal, 19,998 apt)\n",
      "    Threshold: 0.9999 | F1: 0.2038 | PR-AUC: 0.1117 | Sens: 0.4318\n",
      "  Fold 2: Training on 4,019,627 samples (3,999,629 Normal, 19,998 apt)\n",
      "    Threshold: 0.9997 | F1: 0.2067 | PR-AUC: 0.1108 | Sens: 0.6966\n",
      "  Fold 3: Training on 4,019,627 samples (3,999,629 Normal, 19,998 apt)\n",
      "    Threshold: 0.9995 | F1: 0.1664 | PR-AUC: 0.0930 | Sens: 0.6404\n",
      "  Fold 4: Training on 4,019,627 samples (3,999,629 Normal, 19,998 apt)\n",
      "    Threshold: 0.9994 | F1: 0.1698 | PR-AUC: 0.0908 | Sens: 0.6629\n",
      "  Fold 5: Training on 4,019,627 samples (3,999,629 Normal, 19,998 apt)\n",
      "    Threshold: 0.9998 | F1: 0.1892 | PR-AUC: 0.0984 | Sens: 0.5506\n",
      "\n",
      "  Ratio 200:1 - Mean Metrics:\n",
      "    Accuracy:    0.9995 (NIR: 0.9999) ✗ Below NIR\n",
      "    Precision:   0.1124\n",
      "    Recall:      0.5965\n",
      "    F1-score:    0.1872\n",
      "    F2-score:    0.3148\n",
      "    Specificity: 0.9996\n",
      "    ROC-AUC:     0.9991\n",
      "    PR-AUC:      0.1010 ⭐ (Key metric for imbalanced data)\n",
      "    MCC:         0.2565\n",
      "    Kappa:       0.1870\n",
      "\n",
      "====================================================================================================\n",
      "=== GRID SEARCH RESULTS SUMMARY ===\n",
      "====================================================================================================\n",
      "ratio  ratio_value  accuracy  precision   recall  f1_score  f2_score  specificity  roc_auc   pr_auc      mcc    kappa      nir beats_nir\n",
      " 10:1           10  0.999599   0.111531 0.491011  0.179412  0.286267     0.999644 0.999470 0.101527 0.231494 0.179294 0.999911        NO\n",
      " 20:1           20  0.999607   0.117107 0.490986  0.186420  0.293093     0.999652 0.999493 0.099694 0.237013 0.186304 0.999911        NO\n",
      " 30:1           30  0.999557   0.106820 0.536338  0.177218  0.294555     0.999598 0.999402 0.097192 0.238116 0.177096 0.999911        NO\n",
      " 40:1           40  0.999509   0.108376 0.601481  0.181159  0.307211     0.999544 0.999514 0.098552 0.251945 0.181037 0.999911        NO\n",
      " 50:1           50  0.999539   0.110044 0.583555  0.183639  0.309195     0.999576 0.998991 0.099339 0.251459 0.183518 0.999911        NO\n",
      " 75:1           75  0.999518   0.103047 0.567186  0.172913  0.293853     0.999556 0.999377 0.093717 0.239746 0.172789 0.999911        NO\n",
      "100:1          100  0.999520   0.104795 0.569688  0.175273  0.296190     0.999558 0.999165 0.093751 0.241816 0.175150 0.999911        NO\n",
      "150:1          150  0.999578   0.115764 0.546834  0.187696  0.304988     0.999618 0.999530 0.100839 0.248050 0.187578 0.999911        NO\n",
      "200:1          200  0.999532   0.112376 0.596476  0.187163  0.314790     0.999568 0.999084 0.100955 0.256465 0.187042 0.999911        NO\n",
      "\n",
      "====================================================================================================\n",
      "=== BEST RATIOS BY METRIC ===\n",
      "====================================================================================================\n",
      "Best Accuracy:   20:1 (Acc=0.9996, Beats NIR: NO)\n",
      "Best F1-score:   150:1 (F1=0.1877)\n",
      "Best F2-score:   200:1 (F2=0.3148)\n",
      "Best PR-AUC:     10:1 (PR-AUC=0.1015) ⭐ RECOMMENDED\n",
      "Best MCC:        200:1 (MCC=0.2565)\n",
      "\n",
      "====================================================================================================\n",
      "=== KEY INSIGHTS ===\n",
      "====================================================================================================\n",
      "1. Focus on PR-AUC (Precision-Recall AUC) - it's better than ROC-AUC for extreme imbalance\n",
      "2. Optimal threshold found per fold using precision-recall curve\n",
      "3. F2-score emphasizes recall (catching threats) over precision\n",
      "4. Models that beat NIR (0.9999): 0/9\n",
      "\n",
      "Recommended ratio for deployment: 10:1 (highest PR-AUC)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, f1_score,\n",
    "    roc_auc_score, matthews_corrcoef, cohen_kappa_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"=== Optimized XGBoost for Extreme Class Imbalance ===\\n\")\n",
    "\n",
    "# Compute scale_pos_weight for extreme imbalance\n",
    "neg_count = sum(y == 0)\n",
    "pos_count = sum(y == 1)\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "\n",
    "print(f\"Class distribution:\")\n",
    "print(f\"  Normal (0): {neg_count:,}\")\n",
    "print(f\"  apt (1): {pos_count:,}\")\n",
    "print(f\"  Imbalance ratio: {scale_pos_weight:.1f}:1\")\n",
    "print(f\"  Base contamination: {pos_count/len(y):.6f}\")\n",
    "print(f\"\\nScale_pos_weight: {scale_pos_weight:.1f}\\n\")\n",
    "\n",
    "# Define ratio range - focus on ranges that make sense for extreme imbalance\n",
    "# Test from 10:1 up to 100:1 to find sweet spot\n",
    "ratio_range = [10, 20, 30, 40, 50, 75, 100, 150, 200]\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Storage for grid search results\n",
    "grid_results = []\n",
    "\n",
    "# Grid search over different SMOTE ratios\n",
    "for ratio in ratio_range:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing Ratio: {ratio}:1 (Normal:apt)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Storage for metrics for this ratio\n",
    "    acc_scores, roc_auc_scores, pr_auc_scores, mcc_scores, kappa_scores, nir_scores = [], [], [], [], [], []\n",
    "    f1_scores, f2_scores, sensitivity_scores, specificity_scores, precision_scores = [], [], [], [], []\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Calculate minority target based on current ratio\n",
    "        minority_target = sum(y_train == 0) // ratio\n",
    "        \n",
    "        # Apply SMOTE\n",
    "        smote = SMOTE(random_state=42, sampling_strategy={1: minority_target}, k_neighbors=5)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Update training data\n",
    "        X_train = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "        y_train = pd.Series(y_resampled, name='is_apt')\n",
    "        \n",
    "        print(f\"  Fold {fold}: Training on {len(X_train):,} samples ({sum(y_train==0):,} Normal, {sum(y_train==1):,} apt)\")\n",
    "        \n",
    "        # Initialize XGBoost with optimized parameters for imbalanced data\n",
    "        xgb_model = xgb.XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            n_estimators=300,  # More trees for better learning\n",
    "            device=\"cuda\",\n",
    "            learning_rate=0.05,  # Lower learning rate for better convergence\n",
    "            max_depth=4,  # Slightly deeper for more complex patterns\n",
    "            subsample=0.8,\n",
    "            min_child_weight=1,\n",
    "            colsample_bytree=0.8,\n",
    "            scale_pos_weight=scale_pos_weight,  # Critical for imbalance\n",
    "            eval_metric=\"aucpr\",  # PR-AUC better for imbalanced data\n",
    "            gamma=0.1,  # Regularization to prevent overfitting\n",
    "            reg_alpha=0.1,  # L1 regularization\n",
    "            reg_lambda=1.0,  # L2 regularization\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Fit model\n",
    "        xgb_model.fit(X_train, y_train, verbose=False)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold using precision-recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        f1_scores_at_thresholds = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "        optimal_idx = np.argmax(f1_scores_at_thresholds)\n",
    "        optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5\n",
    "        \n",
    "        # Predict using optimal threshold\n",
    "        y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        pr_auc = average_precision_score(y_test, y_prob)  # Better than ROC-AUC for imbalanced\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # F2-score (weights recall 2x more than precision)\n",
    "        f2 = (5 * precision[optimal_idx] * recall[optimal_idx]) / (4 * precision[optimal_idx] + recall[optimal_idx] + 1e-10)\n",
    "        \n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        most_freq_class = y_test.mode()[0]\n",
    "        nir = (y_test == most_freq_class).mean()\n",
    "        \n",
    "        # Store metrics\n",
    "        acc_scores.append(acc)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        pr_auc_scores.append(pr_auc)\n",
    "        mcc_scores.append(mcc)\n",
    "        kappa_scores.append(kappa)\n",
    "        f1_scores.append(f1)\n",
    "        f2_scores.append(f2)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        specificity_scores.append(specificity)\n",
    "        precision_scores.append(prec)\n",
    "        nir_scores.append(nir)\n",
    "        \n",
    "        print(f\"    Threshold: {optimal_threshold:.4f} | F1: {f1:.4f} | PR-AUC: {pr_auc:.4f} | Sens: {sensitivity:.4f}\")\n",
    "        \n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate means for this ratio\n",
    "    mean_acc = np.mean(acc_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_f2 = np.mean(f2_scores)\n",
    "    mean_sens = np.mean(sensitivity_scores)\n",
    "    mean_spec = np.mean(specificity_scores)\n",
    "    mean_prec = np.mean(precision_scores)\n",
    "    mean_roc_auc = np.mean(roc_auc_scores)\n",
    "    mean_pr_auc = np.mean(pr_auc_scores)\n",
    "    mean_mcc = np.mean(mcc_scores)\n",
    "    mean_kappa = np.mean(kappa_scores)\n",
    "    mean_nir = np.mean(nir_scores)\n",
    "    \n",
    "    # Store results\n",
    "    grid_results.append({\n",
    "        'ratio': f\"{ratio}:1\",\n",
    "        'ratio_value': ratio,\n",
    "        'accuracy': mean_acc,\n",
    "        'precision': mean_prec,\n",
    "        'recall': mean_sens,\n",
    "        'f1_score': mean_f1,\n",
    "        'f2_score': mean_f2,\n",
    "        'specificity': mean_spec,\n",
    "        'roc_auc': mean_roc_auc,\n",
    "        'pr_auc': mean_pr_auc,\n",
    "        'mcc': mean_mcc,\n",
    "        'kappa': mean_kappa,\n",
    "        'nir': mean_nir,\n",
    "        'beats_nir': 'YES' if mean_acc > mean_nir else 'NO'\n",
    "    })\n",
    "    \n",
    "    # Print summary for this ratio\n",
    "    print(f\"\\n  Ratio {ratio}:1 - Mean Metrics:\")\n",
    "    print(f\"    Accuracy:    {mean_acc:.4f} (NIR: {mean_nir:.4f}) {'✓ BEATS NIR' if mean_acc > mean_nir else '✗ Below NIR'}\")\n",
    "    print(f\"    Precision:   {mean_prec:.4f}\")\n",
    "    print(f\"    Recall:      {mean_sens:.4f}\")\n",
    "    print(f\"    F1-score:    {mean_f1:.4f}\")\n",
    "    print(f\"    F2-score:    {mean_f2:.4f}\")\n",
    "    print(f\"    Specificity: {mean_spec:.4f}\")\n",
    "    print(f\"    ROC-AUC:     {mean_roc_auc:.4f}\")\n",
    "    print(f\"    PR-AUC:      {mean_pr_auc:.4f} ⭐ (Key metric for imbalanced data)\")\n",
    "    print(f\"    MCC:         {mean_mcc:.4f}\")\n",
    "    print(f\"    Kappa:       {mean_kappa:.4f}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"=== GRID SEARCH RESULTS SUMMARY ===\")\n",
    "print(\"=\"*100)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find best ratio for each metric\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"=== BEST RATIOS BY METRIC ===\")\n",
    "print(\"=\"*100)\n",
    "best_acc = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "best_f1 = results_df.loc[results_df['f1_score'].idxmax()]\n",
    "best_f2 = results_df.loc[results_df['f2_score'].idxmax()]\n",
    "best_pr_auc = results_df.loc[results_df['pr_auc'].idxmax()]\n",
    "best_mcc = results_df.loc[results_df['mcc'].idxmax()]\n",
    "\n",
    "print(f\"Best Accuracy:   {best_acc['ratio']} (Acc={best_acc['accuracy']:.4f}, Beats NIR: {best_acc['beats_nir']})\")\n",
    "print(f\"Best F1-score:   {best_f1['ratio']} (F1={best_f1['f1_score']:.4f})\")\n",
    "print(f\"Best F2-score:   {best_f2['ratio']} (F2={best_f2['f2_score']:.4f})\")\n",
    "print(f\"Best PR-AUC:     {best_pr_auc['ratio']} (PR-AUC={best_pr_auc['pr_auc']:.4f}) ⭐ RECOMMENDED\")\n",
    "print(f\"Best MCC:        {best_mcc['ratio']} (MCC={best_mcc['mcc']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"=== KEY INSIGHTS ===\")\n",
    "print(\"=\"*100)\n",
    "print(\"1. Focus on PR-AUC (Precision-Recall AUC) - it's better than ROC-AUC for extreme imbalance\")\n",
    "print(\"2. Optimal threshold found per fold using precision-recall curve\")\n",
    "print(\"3. F2-score emphasizes recall (catching threats) over precision\")\n",
    "print(f\"4. Models that beat NIR ({results_df['nir'].iloc[0]:.4f}): {sum(results_df['beats_nir'] == 'YES')}/{len(results_df)}\")\n",
    "print(f\"\\nRecommended ratio for deployment: {best_pr_auc['ratio']} (highest PR-AUC)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads_5984",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
